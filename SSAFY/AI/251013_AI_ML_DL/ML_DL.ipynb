{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2c22ac1",
   "metadata": {},
   "source": [
    "# <span style=\"background-color: #E9DCFF\">🦾 AI & 기계학습 기초 1\n",
    "##### AI와 ML은 무엇인가?\n",
    "\n",
    "> CONTENTS\n",
    "1. AI, ML, DL의 정의\n",
    "2. 데이터와 학습의 이해\n",
    "  1. 데이터 구성 요소(Feature/Label)\n",
    "  2. ML 실생활 예시\n",
    "3. 단일 피쳐 기반 학습\n",
    "  1. 1D 피쳐 기반 학습\n",
    "  2. 모델과 가설공간\n",
    "  3. 학습이란\n",
    "4. 복수 피쳐 기반 학습\n",
    "  1. 2D 피쳐 기반 학습\n",
    "  2. 일반적 용어 정리 및 모델 가정\n",
    "  3. 왜 $f(X)$를 학습하는가?\n",
    "\n",
    "<br>\n",
    "\n",
    "> 학습 목표\n",
    "- AI, ML, DL의 저의 및 관계를 학습합니다.\n",
    "- 데이터(feature 및 label), 가설공간, 모델(model)의 개념을 학습합니다.\n",
    "- 학습(learning)의 정의를 학습합니다.\n",
    "\n",
    "<br>\n",
    "\n",
    "## 0. 학습 시작(overview)\n",
    "> AI와 머신러닝(ML)이 내 일상에 미치는 영향\n",
    "- 유튜브는 어떻게 내 취향을 알아맞힐까?\n",
    "- 이메일은 어떻게 스팸/정상을 가려낼까?\n",
    "- 공통점: 사람이 모든 규칙을 미리 코딩하지 않아도, 데이터에서 규칙을 학습해 성능을 향상함.\n",
    "\n",
    "![image](./img/s1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21584f77",
   "metadata": {},
   "source": [
    "## 1. AI, ML, DL의 정의\n",
    "> AI(Artificial Intelligence)\n",
    "- 주어진 환경/데이터를 인지∙학습∙추론을 통해 목표를 달성하도록 예측∙행동 선택∙계획을 하는 시스템\n",
    "> ML(Machine Learning)\n",
    "- AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 접근 방법론\n",
    "- 예: 언어 모델, 이미지 분류 모델, 추천 시스템\n",
    "\n",
    "> DL(Deep Learning)\n",
    "- ML 범주 내에서 신경망(Neural Network) 함수를 사용한 학습 방법론\n",
    "\n",
    "> AI-ML(ML이 아닌 AI 시스템)의 예\n",
    "- 규칙 기반 시스템\n",
    "- 휴리스틱 기반 (최적화) 알고리즘\n",
    "\n",
    "![image](./img/s2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd6806",
   "metadata": {},
   "source": [
    "## 2. 데이터와 학습의 이해\n",
    "### 2-1. 데이터 구성요소 (Feature/Label)\n",
    "> 데이터가 왜 중요한가?\n",
    "- 머신러닝은 규칙을 직접 코딩하지 않고, 데이터에서 규칙을 학습\n",
    "- 데이터(Feature, Label)의 분포와 관계가 머신러닝의 학습 결과를 결정\n",
    "> Feature(피처, 특성)\n",
    "- 모델이 예측에 사용하는 입력정보\n",
    "- 예측, 판단의 근거/단서\n",
    "> Label(라벨, 목표값)\n",
    "- 모델이 예측하려는 정답\n",
    "- 학습의 목표값\n",
    "\n",
    "![image](./img/s3.png)\n",
    "\n",
    " <br>\n",
    "\n",
    "### 2-2. ML 실생활 예시\n",
    "> 예시 1 - 유튜브 추천\n",
    "- Feature: 각 영상들의 정보(장르, 크리에이터, 조회수, 좋아요 수 등), 사용자 정보(시청 이력, 구독 채널 등)\n",
    "- Label: 영상에 대한 사용자 피드백(시청 여부, 좋아요 클릭 여부)\n",
    "> 예시 2 - 스팸메일 분류\n",
    "- Feature: 메일 제목, 발신자, 단어 빈도\n",
    "- Label: 스팸/정상\n",
    "\n",
    "![image](./img/s4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aac125",
   "metadata": {},
   "source": [
    "## 3. 단일 피쳐 기반 학습\n",
    "### 3-1. 1D 피쳐 기반 학습\n",
    "> 1D 피쳐 기반 학습(단일 피쳐 학습)이란?\n",
    "- 1D = 1차원\n",
    "- Feature가 하나일 때 머신러닝이 학습하는 가장 단순한 형태\n",
    "\n",
    "![image](./img/s5.png)\n",
    "\n",
    "> $Income_i = f^{*}(\\text{Years of Education}_i) + ϵ_i$\n",
    "<br>\n",
    "$f^*$: 미지의 참 함수\n",
    "- Feature와 Label 사이의 실제 평균 관계\n",
    "- 하지만 직접 관측할 수 없음\n",
    "- 오차가 포함된 데이터(점)만 관측 가능\n",
    "<br>\n",
    "$ϵ_i$: 측정 오차\n",
    "- 데이터에는 주로 측정 오차가 섞여있음\n",
    "- 원인: 측정 기기의 한계, 환경적 요인 등\n",
    "- 따라서, 데이터 = 참 함수 + 오차($f^{*} + ϵ$)\n",
    "\n",
    "- 데이터셋 D: 30명의 Years of Education(피쳐)와 Income(라벨) 쌍\n",
    "- $D = {(\\text{Years of Education}_i, \\text{Income}_i)}^{30}_{i=1}$\n",
    "\n",
    "![image](./img/s6.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "> 피쳐와 라벨의 관계를 잘 나타내는 함수 $f$는 없을까?\n",
    "- 데이터를 설명하는 여러 함수 후보가 존재\n",
    "- 어떤 함수가 가장 잘 맞는지 학습해야 함\n",
    "\n",
    "![image](./img/s7.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3-2. 모델과 가설 공간\n",
    "> 학습(Learning)\n",
    "- \"입력(Feature) → 출력(Label)\" 관계를 찾는 과정\n",
    "- 평균 관계를 하나의 함수로 표현함\n",
    "- 하지만 관계를 표현할 수 있는 함수는 무수히 많음\n",
    "\n",
    "> 가설공간(Hypothesis Space)\n",
    "- 관계를 표현할 수 있는 모든 후보 함수들의 모음\n",
    "- 피쳐 공간과 라벨 공간 위에서 정의된 함수들의 집합$F$\n",
    "\n",
    "> 모델(Model)   \n",
    "- 가설공간 $F$에 속한 특정 함수 $f$\n",
    "\n",
    "![image](./img/s8.png)\n",
    "![image](./img/s9.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 3-3. 학습이란\n",
    "> 학습\n",
    "- 주어진 데이터와 성능척도를 바탕으로 가설공간 $F$의 후보들 중 최적의 모델을 선택하는 과정\n",
    "- 데이터$D$ → 가설공간 $F$ → 선택된 모델 $f$\n",
    "\n",
    "![image](./img/s10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b271738",
   "metadata": {},
   "source": [
    "## 4. 복수 피쳐 기반 학습\n",
    "### 4-1. 2D 피쳐 기반 학습\n",
    "> $Income = f^{*}(\\text{Years of Education}, \\text{Seniority}) + ϵ$\n",
    "<br>\n",
    "$f^*$: 미지의 참 함수(입력과 출력을 이어주는 숨겨진 진짜 함수)\n",
    "- <span style='color: #3399FF'>파란색</span> Surface(=미지의 참 함수 $f$)는 관측 불가능\n",
    "- <span style='color: #FF6666'>빨간색</span> 점들(=데이터)만 관측 가능함\n",
    "- 학습 전: 어떤 가설공간 $F$을 사용할까?\n",
    "- 학습 후: 데이터를 활용하여 어떤 모델 $f$을 선택해야 할까?\n",
    "\n",
    "![image](./img/s11.png)\n",
    "![image](./img/s12.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 4-2. 일반적 용어 정리 및 모델 가정\n",
    "> $Income = f^{*}(\\text{Years of Education}, \\text{Seniority}, ...) + ϵ → Y = f^{*}(X) + ϵ$\n",
    "- Income: 우리가 예측하려는 라벨(반응/목표) 변수 → Y로 표기\n",
    "- Years of Education: 첫 번째 피쳐(입력/예측) 변수 → $X_1$로 표기\n",
    "- Seniority: 두 번째 피쳐(입력/예측) 변수 → $X_2$로 표기\n",
    "- 다른 $i$ 번째 피처가 있다면 역시 $X_i$로 표기\n",
    "- 일반적인 $p$차원 피처(총 $p$개의 피쳐) 벡터: $X = \\begin{bmatrix}X_{1}\\\\X_{2}\\\\...\\\\X_{p}\\\\ \\end{bmatrix} \\in \\mathbb{R}^p$\n",
    "- 모델(함수명): $f^{*}: \\mathbb{R}^{p} → \\mathbb{R}, Y = f^{*}(X) + ϵ$\n",
    "- 측정오차 ϵ: ϵ는 피쳐 $X$와 독립 및 $\\mathbb{E}[ϵ]=0$로 가정함\n",
    "\n",
    "<br>\n",
    "\n",
    "### 4-3. 왜 $f(\\cdot)$를 학습하는가?\n",
    "> 예측\n",
    "- 잘 학습된 $f$가 있으면, 새로운 입력 $X=x$에서 반응/목표 $Y$를 예측할 수 있음\n",
    "\n",
    "> 중요 특성 파악\n",
    "- 피쳐들 $X = (X_{1}, X_{2}, ..., X_{p})$의 어떤 특성이 $Y$를 설명하는 데에 중요하고, 어떤 것은 덜 중요(무관)한지 알 수 있음\n",
    "  - 예: 근속연수(Seniority), 교육기간(Years of Education)은 소득(Income)에 큰 영향을 줄 수 있지만, 혼인 여부(Marital Status)는 영향이 거의 없을 것임\n",
    "\n",
    "> 해석 가능성\n",
    "- $f$의 복잡도에 따라 각 구성요소 $X_j$가 $Y$에 어떻게 영향을 미치는지(증가/감소 방향, 민감도 등) 이해할 수 있음\n",
    "\n",
    "<br>\n",
    "\n",
    "### 연습 문제\n",
    "\n",
    "![image](./img/s13.png)\n",
    "![image](./img/s14.png)\n",
    "![image](./img/s15.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab521ba2",
   "metadata": {},
   "source": [
    "### 요약 정리\n",
    "> AI와 ML\n",
    "- AI: 주어진 환경/데이터를 인지∙학습∙추론하여 목표 달성을 위한 예측∙행동 선택∙계획을 수행하는 시스템\n",
    "- ML: AI 범주 내에서 데이터로부터 학습하여 목적을 달성하는 방법론\n",
    "\n",
    "> 데이터의 구성 요소\n",
    "- Feature: 모델 입력 정보, 예측∙판단의 근거\n",
    "- Label: 모델이 예측하려는 정답, 학습의 목표\n",
    "\n",
    "> 1D 피쳐 기반 학습\n",
    "- Feature가 하나일 때(1차원) 수행되는 단순한 학습 형태\n",
    "- Feature와 Label 사이의 관계를 함수 $f$로 표현하되, 실제 데이터에는 측정오차($ϵ$)가 포함됨\n",
    "\n",
    "> 모델과 가설 공간\n",
    "- 가설 공간($F$): Feature와 Label 관계를 표현할 수 있는 함수들의 집합\n",
    "- 모델: 가설 공간 내 특정 함수 $f$\n",
    "\n",
    "> 학습\n",
    "- 데이터와 성능 척도를 바탕으로 가설 공간 $F$ 내 후보 중 최적의 모델을 선택하는 과정\n",
    "\n",
    "> 모델 학습의 필요성\n",
    "- 예측: 새로운 입력값에 대해 Labele을 추론\n",
    "- 중요 특성 파악: 어떤 Feature가 결과에 중요한지 확인\n",
    "- 해석 가능성: 각 Feathre가 결과에 어떤 영향을 미치는지 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ddda51",
   "metadata": {},
   "source": [
    "# <span style=\"background-color: #E9DCFF\">🦾 AI & 기계학습 기초 2\n",
    "##### 지도학습은 무엇인가?\n",
    "\n",
    "> CONTENTS\n",
    "1. 지도학습의 개념\n",
    "2. 회귀(Regression)\n",
    "3. 분류(Classification)\n",
    "4. 학습의 목적\n",
    "\n",
    "<br>\n",
    "\n",
    "> 학습 목표\n",
    "- 회귀(연속값)와 분류(범주값)의 문제 정의와 출력 차이 이해\n",
    "- 문제 유형에 맞는 오류/평가지표를 바르게 선택∙해석\n",
    "- 학습의 목적: 테스트 성능 최대화(테스트 오류 최소화)에 대한 이해\n",
    "- 오버피팅(overfitting)의 이해\n",
    "\n",
    "## 0. 학습 시작(overview)\n",
    "> 지도 학습: \"훈련 데이터가 아니라, 처음 보는 데이터에서의 예측 성능 향상\"\n",
    "- 지도학습은 입력 + 정답(레이블)을 가지고 예측 규칙을 배우는 방법\n",
    "- 이미 갖고 있는 데이터를 활용하여 학습하지만, 궁극적으로 새로운 데이터에서의 예측을 잘하조가 하는 데에 초점\n",
    "<br>예. 어제까지 고객 데이터로 \"내일 이탈할 고객\" 미리 알기, 기존 거래 사기(Fraud) 데이터로 새로운 사기 탐지\n",
    "\n",
    "![image](./img/s16.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de1364",
   "metadata": {},
   "source": [
    "## 1. 지도학습의 개념\n",
    "### 1-1. 지도학습(supervised learning)이란?\n",
    "> 데이터\n",
    "- 입력(특성)과 정답(라벨)이 쌍으로 있는 데이터\n",
    "> 목표\n",
    "- 새 입력이 들어오면 정답을 잘 맞추는 규칙을 학습\n",
    "> 지도학습의 종류\n",
    "- 회귀: 예측값이 숫자(가격, 점수, 온도)\n",
    "- 분류: 예측값이 범주(스팸/정상, 질병 유/무)\n",
    "\n",
    "![image](./img/s17.png)\n",
    "\n",
    "> 특성(Feature, $x$)\n",
    "- 예측에 쓰는 설명 변수\n",
    "  - 예: 집값 예측 {지역, 평수, 방수, 연식}, 이메일 스팸 필터링 {제목, 내용 텍스트, 송신인}\n",
    "\n",
    "> 라벨(Label, $y$)\n",
    "- 맞춰야 하는 정답\n",
    "  - 예: 집값, 스팸/정상 이메일\n",
    "\n",
    "> 예측값($\\hat{y}$)\n",
    "- 모델이 내놓은 결과(숫자 또는 범주)\n",
    "\n",
    "> 오류(Error)\n",
    "- 예측값($\\hat{y}$)과 라벨($y$)의 차이: $\\hat{y} - y$\n",
    "\n",
    "![image](./img/s18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501ef2f4",
   "metadata": {},
   "source": [
    "## 2. 회귀(Regression)\n",
    "### 2-1. 회귀(Regression)문제\n",
    "> 입력으로부터 숫자를 얼마나 정확히 예측할까?\n",
    "- Feature: 면적∙방수∙연식 → Label: 집값(원 단위)\n",
    "- Feature: 매체별 광고비(TV/라디오/온라인) → Label: 매출액\n",
    "\n",
    "> 라벨 및 예측 모델의 출력\n",
    "- 연속적인 수치\n",
    "\n",
    "![image](./img/s19.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2-2. 회귀 오류: 평균제곱오차(MSE)\n",
    "> 평균제곱오차(Mean Squared Error)\n",
    "- 각 데이터에서 정답($y_i$)과 예측($\\hat{y}_i$)의 평균 제곱 차이값\n",
    "<br> $MSE = \\frac{1}{n} \\sum\\limits_{i=1}^{n} (y{i} - \\hat{y_{i}})^2$\n",
    "\n",
    "> 해석\n",
    "- 큰 오류를 더 크게 벌주므로, 전체 오류 수준을 한눈에 봄\n",
    "\n",
    "> 참고\n",
    "- 데이터와 같은 단위를 쓰고싶으면 RMSE(MSE의 제곱근)도 사용\n",
    "<br> $RMSE = \\sqrt{MSE} = \\sqrt{\\frac{1}{n} \\sum\\limits_{i=1}^{n} (y{i} - \\hat{y_{i}})^2}$\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2-3. 회귀 설명력: $R^2$ (결정계수)\n",
    "> 결정계수\n",
    "- 라벨의 분산 중에서 특성으로 설명되는 비율\n",
    "- \"평균만 쓰는 단순한 예측\"보다 얼마나 더 잘 맞추는지를 0~1 사이로 나타낸 값\n",
    "<br> $R^{2} = 1 - \\frac{\\sum_{i=1}^{n} (y{i} - \\hat{y_{i}})^2}{\\sum_{i=1}^{n} (y{i} - \\hat{y_{i}})^2}$      ($\\bar{y} = y_i$들의 평균값)\n",
    "\n",
    "> 해석\n",
    "- 1에 가까울수록 설명력이 높고, 낮을수록 설명력이 낮음\n",
    "\n",
    "> 질문\n",
    "- $R^2$가 음수가 나올 수 있을까?\n",
    "  <br> 예측값 ($\\hat{y}_i$)들이 평균값 $\\bar{y}$보다도 못하다면 나올 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2366abda",
   "metadata": {},
   "source": [
    "## 3. 분류(Classification)\n",
    "### 3-1. 분류(Classfication) 문제\n",
    "> 입력으로부터 범주는 얼마나 정확히 가려낼까?\n",
    "- Feature: 메일 내용∙보낸이 이메일 주소 → Label: 스팸/정상\n",
    "- Feature: 종양 반경, 면적 → Label: 악성/양성\n",
    "\n",
    "> 라벨\n",
    "- 범주 라벨(이진/다중)\n",
    "\n",
    "![image](./img/s20.png)\n",
    "\n",
    "### 3-2. 분류 정확도(Accuracy)\n",
    "\n",
    "> 정확도\n",
    "- 전체 중 맞춘 비율\n",
    "<br> $Accuracy = \\frac{1}{n} \\sum\\limits_{i=1}^{n} Ⅱ(y{i} = \\hat{y_{i}})$\n",
    "<br> Ⅱ: 지시(indicator) 함수\n",
    "<br> Ⅱ(A)  = 1 if A true\n",
    "\n",
    "> 정확도만 보면 발생하는 문제\n",
    "- 불균형 데이터(양성 1%, 음성 99%)에서는 전부 음성이라 해도 정확도가 99%로 보일 수 있음\n",
    "\n",
    "> 결론\n",
    "- 정확도만 보지 말고 다른 지표도 함께 봐야 안전\n",
    "\n",
    "### 3-3. 혼동행렬(Confusion Matrix)\n",
    "> 혼동행렬\n",
    "- 예측과 실제 값 사이의 관계를 행렬 형태로 표현\n",
    "- TP: 실제 양성, 예측도 양성\n",
    "- TN: 실제 음성, 예측도 음성\n",
    "- FP: 실제는 음성인데 양성이라 함(오탐)\n",
    "- FN: 실제는 양성인데 음성이라 함(누락)\n",
    "\n",
    "![image](./img/s21.png)\n",
    "\n",
    "> 정밀도(Precision)\n",
    "- \"양성이라 판정한 것 중\" 진짜 양성의 비율 = TP/(TP+FP)\n",
    "> 재현율(Sensitivity or Recall)\n",
    "- \"진짜 양성 가운데\" 잡아낸 예측 양성 비율 = TP/(TP+FN)\n",
    "> F1-score\n",
    "- 정밀도와 재현율의 조화평균\n",
    "  <br> $F1 = 2 {\\times} \\frac{\\text{정밀도} {\\times} \\text{재현율}}{\\text{정밀도 + 재현율}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c3d318",
   "metadata": {},
   "source": [
    "## 4. 학습의 목적\n",
    "### 4-1. 학습의 목적\n",
    "> 학습의 목적은 테스트 예측(일반화)\n",
    "- 학습 모델의 성능 평가는 모델이 처음 보는(학습에 사용되지 않은) 데이터로 평가\n",
    "  - 일반화(generalization) 오류의 최소화 지향\n",
    "- 훈련 데이터에서 성능이 아무리 좋아도, 새로운 데이터에서 성능이 떨어지면 시전엔 사용할 수 없음\n",
    "- 다음 차시(3차시)에서 일반화 성능을 추정 (검증/교차검증)하는 방법을 배울 예정\n",
    "\n",
    "<br>\n",
    "\n",
    "### 4-2. 오버피팅(overfitting)이란?\n",
    "> 오버피팅(overfitting)\n",
    "- 훈련 데이터의 우연한 패턴/잡음까지 외워버려서 (초록색 함수) 훈련에서는 잘 맞지만 테스트에서는 성능이 나빠지는 현상\n",
    "- 현상: 훈련 오류 급격히 낮음, 테스트 오류 높음/요동\n",
    "<br>\n",
    "\n",
    "> 오버피팅 왜 안 좋은가?\n",
    "- 표본(sample) 의존∙불안정: 훈련 데이터는 모집단의 일부 표본이라 우연한 잡음이 섞임. 이것에만 과하게 맞추어 학습하면 샘플 몇 개만 바뀌어도 예측이 크게 흔들림 (분산↑)\n",
    "- 일반화 실패: 보지 못한 데이터(테스트) 오류가 커짐, 모(population)집단 성능과 격차가 벌어짐.\n",
    "\n",
    "![image](./img/s22.png)\n",
    "\n",
    "<br>\n",
    "> 오버피팅 ≠ 분포 변화(distribution shift)로 인한 에러 증가\n",
    "- 분포 변화로 인한 오류: 훈련 데이터 분포와 테스트 분포의 다름으로(환경∙계절∙센서 변경 등) 성능이 떨어지는 현상\n",
    "- 분포 변화로 인한 에러 증가는 모델이 과적합하지 않아도 발생 가능\n",
    "\n",
    "![image](./img/s23.png)\n",
    "![image](./img/s24.png)\n",
    "\n",
    "<br>\n",
    "> 오버피팅 vs 언더피팅(균형 잡기)\n",
    "- 오버피팅: 모델이 너무 복잡 → 잡음까지 학습(테스트 성능 나쁨)\n",
    "- 언더피팅: 모델이 단순하거나 학습이 완료되지 않음 → 중요한 패턴을 놓침(오류 큼)\n",
    "> 해결 실마리\n",
    "- 더 많은 데이터, 테스트 데이터를 활용한 모델 선정. 교차 검증(3차시)\n",
    "\n",
    "![image](./img/s25.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "### 확인문제\n",
    "![image](./img/s26.png)\n",
    "![image](./img/s27.png)\n",
    "![image](./img/s28.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5de2baa",
   "metadata": {},
   "source": [
    "### 강의 정리\n",
    "> 지도학습(Supervised Learning)\n",
    "- 입력(Feature)과 정답(Label)이 쌍으로 있는 데이터로 학습\n",
    "- 새로운 입력에 대해 정답을 잘 예측하는 규칙을 찾는 과정\n",
    "- 종류\n",
    "  - 회귀(Regression): 연속적인 값 예측(집값, 점수, 매출액)\n",
    "  - 분류(Classification): 범주 예측(스팸/정상, 질병 유무)\n",
    "\n",
    "> 회귀 평가 지표\n",
    "- MSE(평균제곱오차): 큰 오류를 더 크게 반영해 전체 오류 수준을 파악\n",
    "- $R^2$(결정계수): 모델이 데이터를 얼마나 설명하는지 (0~1 사이, 높을수록 설명력 큼)\n",
    "\n",
    "> 분류 평가 지표\n",
    "- 정확도(Accuracy): 전체 중 맞춘 비율(불균형 데이터에서 한계 존재)\n",
    "- 혼동행렬(Confusion Matrix): 예측 vs 실제를 행렬로 표현\n",
    "\n",
    "> 학습의 목적\n",
    "- 일반화(Generalization): 처음 보는 데이터에서도 잘 작동해야 함\n",
    "- 훈련 데이터 성능만 좋고 실제 성능이 낮으면 활용 불가\n",
    "\n",
    "> 오버피팅(Overfitting)\n",
    "- 훈련 데이터의 잡음까지 학습 → 훈련 성능↑, 테스트 성능↓\n",
    "- 특징: 훈련 오류 작음, 테스트 오류 큼\n",
    "\n",
    "> 언더피팅(Underfitting)\n",
    "- 모델이 너무 단순하거나 학습이 부족 → 중요한 패턴을 놓침\n",
    "- 특징: 훈련/테스트 모두 오류 큼\n",
    "\n",
    "> 균형 잡기(Overfitting vs Underfitting)\n",
    "- 오버피팅: 모델이 너무 복잡 → 과적합\n",
    "- 언더피팅: 모델이 너무 단순 → 과소적합\n",
    "- 해결 방법: 더 많은 데이터 확보, 테스트 데이터를 활용한 모델 선정, 교차 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d4b6b",
   "metadata": {},
   "source": [
    "# <span style=\"background-color: #E9DCFF\">🦾 AI & 기계학습 기초 3\n",
    "##### 교차검증(Cross-Validation)\n",
    "\n",
    "> CONTENTS\n",
    "1. 테스트 성능 평가\n",
    "2. 검증셋(validation set) 접근\n",
    "3. K-겹 교차검증 (K-fold Cross-Validation)\n",
    "\n",
    "<br>\n",
    "\n",
    "> 학습 목표\n",
    "- 훈련 오류 vs 테스트 오류의 차이를 말하고, 왜 테스트 예측(일반화)이 목표인지 설명한다.\n",
    "- 검증셋(hold-out), K-겹 교차검증(K-fold Cross-Validation)의 개념을 배운다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9bfba5",
   "metadata": {},
   "source": [
    "## 1. 테스트 성능 평가\n",
    "> 훈련 오류 vs 테스트 오류\n",
    "- 훈련 오류: 모델을 학습시킨 같은 데이터에 적용해 계산한 오류\n",
    "- 테스트 오류: 학습에 쓰지 않은 새 관측치에 대해 모델을 적용했을 떄의 평균 예측 오류\n",
    "- 보통 훈련 오류는 테스트 오류와 다르며, 특히 오류는 테스트 오류를 (심하게) 과소평가하는 경우가 많음.\n",
    "  <br>예. 암기 vs 응용 시험\n",
    "\n",
    "![image](./img/s29.png)\n",
    "\n",
    "> 훈련 오류 vs 테스트 오류\n",
    "- <span style=\"color: #3399FF\">파란색</span> 선: 훈련 오류\n",
    "- <span style=\"color: #FF6666\">빨간색</span> 선: 테스트 오류\n",
    "- 훈련 오류는 계속 ↓, 테스트 오류는 U자형\n",
    "- 목적: 테스트 오류의 U자형의 바닥이 되도록 하는 적절한 모델 찾기\n",
    "\n",
    "![image](./img/s30.png)\n",
    "\n",
    "> 테스트 예측오류 계산\n",
    "- 이상적 케이스: 충분히 큰 별도 테스트 데이터셋 → 현실에선 구하기 어려움\n",
    "- 현실에서는 테스트만을 위한 데이터를 갖기에 데이터 자체가 부족할 수 있음\n",
    "\n",
    "> 대안: 재표본화(resampling)를 통한 테스트 오류 추정\n",
    "- 데이터를 나눠 여러 번 \"훈련 → 평가\"를 반복해 테스트 오류를 가늠\n",
    "- 방법: 검증셋(hold-out), K겹 교차검증(K-fold Cross-Validation)\n",
    "- 장점: 별도의 테스트 데이터 없이 데이터를 더 효율적으로 사용하여 일반화 오차 추정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d8912d",
   "metadata": {},
   "source": [
    "## 2. 검증셋(Validation Set) 접근\n",
    "### 2-1. 검증셋(Validation Set) 방법\n",
    "> 검증셋(홀드아웃) 방법\n",
    "- 가용 샘플들을 무작위로 훈련셋과 검증셋(hold-out)으로 분할\n",
    "- 훈련셋으로 모델 적합, 검증셋으로 예측 후 검증 오류를 계산\n",
    "- 검증 오류는 보통 정량 반응은 MSE, 범주 반응은 오분류율(또는 F1-score)을 측정한다.\n",
    "\n",
    "![image](./img/s31.png)\n",
    "\n",
    "### 2-2. 검증셋 절차\n",
    "> 검증 절차\n",
    "- 데이터 순서 무작위 셔플링 후 두 부분으로 분할: 왼쪽(파랑)=훈련셋, 오른쪽(주황)=검증셋\n",
    "- 학습은 훈련셋에서, 성능평가는 검증셋에서 수행\n",
    "\n",
    "![image](./img/s32.png)\n",
    "\n",
    "> 예시: 자동차 데이터\n",
    "- 목표: 선형(1차) 모델부터 고차항(다항식) 모델 비교\n",
    "- 392개 데이터를 무작위로 196개 훈련셋/196개 검증셋으로 분할 (일반적으로 반으로 나눌 필요는 없음)\n",
    "- 좌측 패널: 단 한 번 분할 시의 MSE 곡선\n",
    "- 우측 패널: 여러 번 (셔플 후) 다른 분할의 MSE 곡선들\n",
    "\n",
    "![image](./img/s33.png)\n",
    "\n",
    "> 예시에서 보이는 검증셋 방법의 단점이 무엇일까?\n",
    "- 어떤 표본이 훈련/검증에 들어가느냐에 따라 검증 기반 테스트 오류 추정치가 매우 가변적\n",
    "- 검증 접근엥서는 훈련셋(=전체의 일부)만으로 모델을 학습하기에 적합하므로, 전체 데이터로 학습했을 때보다 성능이 낮게 추정(즉, 테스트 오류를 과대 추정)될 수 있음\n",
    "> 왜 전체 데이터로 학습한 모델의 테스트 오류를 과대 추정하는 경향이 있을까?\n",
    "  <br>학습에 데이터를 부분적으로 사용하기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508df2f7",
   "metadata": {},
   "source": [
    "## 3. K-겹 교차검증(K-fold Cross-Validation)\n",
    "### 3-1. K-겹 교차검증\n",
    "> K-겹 교차검증(K-fold Cross-Validation)\n",
    "- 테스트 오류 추정의 표준적 접근\n",
    "- 추정치는 모델 선택과 최종 모델의 테스트 오류 규모 파악에 활용\n",
    "- 데이터 전체를 크기 동일한 K개 폴드로 무작위 분할\n",
    "  <br> → 폴드 K∈{1, 2, ..., K}를 검증, 나머지 K-1개를 훈련에 사용\n",
    "  - k=1, ..., K에 대해 반복 후, 평균 오류로 테스트 오류를 추정\n",
    "\n",
    "> K-겹 교차검증 단계\n",
    "- 데이터를 먼저 셔플링한 뒤, 총 n개의 데이터를 겹치지 않는 K개 그룹으로 분할\n",
    "- 각 그룹이 번갈아 검증셋(주황), 나머지는 훈련셋(파랑)\n",
    "- K개의 MSE를 평균해 테스트 오류를 추정\n",
    "\n",
    "![image](./img/s34.png)\n",
    "\n",
    "> K-겹 교차검증 오류 계산\n",
    "- 폴드 집합 $C_1, ..., C_K$, 각 폴드 크기 $n_k$\n",
    "<br>$CV(K) =\\sum\\limits_{i=1}^{n} \\frac{n_k}{n} MSE_k$\n",
    "- 여기서, $MSE_k = \\frac{1}{n_k} \\sum_{i {\\in} C_k} (y_i - \\hat{y_i})^2$\n",
    "  <br> k-폴드를 검증셋으로 두고 나머지로 적합한 예측 $\\hat{y}_i$\n",
    "- K=n이면 Leave-One-Out 교차검증(LOOCV)\n",
    "\n",
    "> Leave-One-Out 교차검증에서 검증셋 크기는?\n",
    "\n",
    "<br>\n",
    "\n",
    "> Leave-One-Out 교차검증\n",
    "- 훈련셋(파랑): 관측치 하나만 제외한 나머지 전부\n",
    "- 검증셋(주황): 제외한 1개 관측치\n",
    "- 이 과정을 n번 반복해 나온 n개의 MSE 평균으로 테스트 오류를 추정\n",
    "\n",
    "![image](./img/s35.png)\n",
    "\n",
    "> Leave-One-Out 교차검증 vs 10-겹 교차검증\n",
    "- 자동차 데이터에서 LOOCV와 10-겹 CV 결과 비교(다항 차수에 따른 MSE 곡선)\n",
    "- 두 방법의 경향과 최적 차수가 비슷\n",
    "\n",
    "![image](./img/s36.png)\n",
    "\n",
    "> 시뮬레이션: 참/추정 테스트 MSE\n",
    "- 파랑: 참(test) MSE, 검은 점선: LOOCV 추정, 주황: 10-겹 CV 추정\n",
    "- 10-겹 CV 추정: 테스트 성능에 추정의 좋은 대안\n",
    "\n",
    "![image](./img/s37.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c626f881",
   "metadata": {},
   "source": [
    "### 연습문제\n",
    "\n",
    "![image.png](./img/s38.png)\n",
    "![image.png](./img/s39.png)\n",
    "![image.png](./img/s40.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f89fe",
   "metadata": {},
   "source": [
    "### 강의 정리\n",
    "> 테스트 성능 평가\n",
    "- 훈련 오류: 학습에 사용된 데이터에서의 오류\n",
    "- 테스트 오류: 새 데이터에서의 오류 → 일반화 성능 평가 기준\n",
    "- 목표: 테스트 오류가 최소가 되는 모델 선택\n",
    "\n",
    "> 오버피팅 vs 언더피팅\n",
    "- 오버피팅: 모델이 지나치게 복잡 → 훈련 성능↑, 테스트 성능↓\n",
    "- 언더피팅: 모델이 지나치게 단순 → 중요한 패턴을 놓쳐 오류 큼\n",
    "\n",
    "> 검증(Validation)\n",
    "- 데이터를 훈련셋/검증셋으로 분리\n",
    "- 훈련셋으로 모델 적합, 검증셋으로 성능 측정\n",
    "- Hold-out, K겹 교차검증(Cross-Validation) 활용\n",
    "\n",
    "> K겹 교차검증\n",
    "- 데이터를 K개로 나눠 반복적으로 학습∙평가\n",
    "- 모든 데이터를 검증에 사용해 일반화 성능을 더 정확히 추정\n",
    "- $K = n$:LOOCV (Leave-One-Out Cross Validation)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
