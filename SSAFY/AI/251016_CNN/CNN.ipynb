{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6785d36",
   "metadata": {},
   "source": [
    "# ⭐ 딥러닝 및 이미지 모델\n",
    "## \"1차시: 이미지 딥러닝 모델\"\n",
    "> CONTENT\n",
    "1. CNN 살펴보기\n",
    "  1. CNN vs FCN\n",
    "  2. 모델구조\n",
    "2. CNN 기반 모델 변천사\n",
    "  1. AlexNet\n",
    "  2. VGGNet\n",
    "  3. ResNet\n",
    "  4. MobileNet\n",
    "<br>\n",
    "<br>\n",
    "> 학습 목표\n",
    "- 이미지  기반 학습 모델의 구조와 작동 방식을 이해합니다.\n",
    "- 대표적 CNN 기반 이미지 모델의 변천사를 배웁니다.\n",
    "- 이미지 분류 문제에서 실습을 통해 주요 이미지 모델을 적용해봅니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a851bc6e",
   "metadata": {},
   "source": [
    "## 0. 학습 시작(오버뷰)\n",
    "> CNN 모델의 기본 구조는 무엇이며, 왜 이미지 과업에서 중요한가?\n",
    "- CNN 모델의 기원 및 모델 주요 모듈 소개\n",
    "> CNN의 단위 연산과 디자인 철학은 어떻게 발전했을까?\n",
    "- 계층 깊이, 스케일, 학습 방법, 경량화\n",
    "> CNN 기반 주요 모델은 어떻게 변화해왔고, 왜 중요한가?\n",
    "- 깊이와 효율성을 동시에 높이는 방향으로 개선\n",
    "<br>\n",
    "<br>\n",
    "> 산업 현장 사례\n",
    "- 금형 표면 스크래치 검출\n",
    "- 식품/의약품의 이물질 검출\n",
    "- PCB 불량 자동 판정\n",
    "  <br> 부품과 기판 사이의 접합이 불완전한 냉땜, 표면에 남은 플럭스 잔여물, 납땜부 미세 크랙 등 불량 검출\n",
    "\n",
    "> 내 일상 속에서 찾아볼 수 있는 사례\n",
    "- 성동구, 픽토그램 활용 '안심우회전시설' 첫 설치\n",
    "- 인공지능(AI) 카메라를 이용하여 차량, 보행자 등을 실시간으로 감지\n",
    "- 상황에 맞게 움직이는 픽토그램을 모니터로 표출하는 방식으로 교통사고를 효율적으로 예방\n",
    "\n",
    "![image.png](./img/cnn1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c9478",
   "metadata": {},
   "source": [
    "## 1. CNN 살펴보기\n",
    "### 1-1. CNN vs FCN\n",
    "\n",
    "> 완전 연결층(Fully-Connected Layer)\n",
    "- 입력을 받아서 출력으로 변환하는 신경망의 기본 모듈\n",
    "- FCN 변환 예씨\n",
    "  - 입력: 이미지가 32x32x3인 고차행렬이라고 가정(이미지의 높이, 너비가 각각 32픽셀, RGB 값 3개를 의미하여 RGB 값은 0~255 사이) 이미지의 모든 화소를 나열하여 1차원 벡터로 만들어 입력 데이터로 받는다.\n",
    "  - 출력: 10x1의 1차원 벡터\n",
    "  - 모델 상수: 모델이 학습해야 하는 파라미터(parameter)\n",
    "    <br> 상기 입출력 시, 모델상수 W는 10x3072로 입력의 모든 값이 출력에 미치는 영향을 나타냄.\n",
    "![image.png](./img/cnn2.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "> 합성곱 레이어 (Convolution Layer)\n",
    "- 입력 이미지를 필터와 연산하여 특징 맵(feature map)을 뽑아내는 모듈\n",
    "- 1차원 구조로 변환하는 FCN과 달리 3차원 구조를 그대로 보존하면서 연산\n",
    "- Convolution(컨볼루션): 필터를 이미지 상에서 이동시키면서 내적을 반복 수행, 내적으로 구한 모든 값을 출력 제공\n",
    "\n",
    "![image.png](./img/cnn3.png)\n",
    "![image.png](./img/cnn4.png)\n",
    "![image.png](./img/cnn5.png)\n",
    "![image.png](./img/cnn6.png)\n",
    "\n",
    "- 예: 박스필터\n",
    "\n",
    "![image.png](./img/cnn7.png)\n",
    "![image.png](./img/cnn8.png)\n",
    "![image.png](./img/cnn9.png)\n",
    "![image.png](./img/cnn10.png)\n",
    "![image.png](./img/cnn11.png)\n",
    "<br>\n",
    "- 입력 이미지를 필터와 연산하여 특징 맵(feature map)을 뽑아내는 모듈\n",
    "\n",
    "![image.png](./img/cnn12.png)\n",
    "![image.png](./img/cnn13.png)\n",
    "<br>\n",
    "- 출력 해상도 = 입력 해상도 - 필터 해상도 + 1\n",
    "  <br> ex. 8 = 10 - 3 + 1\n",
    "\n",
    "![image.png](./img/cnn14.png)\n",
    "![image.png](./img/cnn15.png)\n",
    "![image.png](./img/cnn16.png)\n",
    "![image.png](./img/cnn17.png)\n",
    "![image.png](./img/cnn18.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0395f",
   "metadata": {},
   "source": [
    "### 1-2. 모델 구조\n",
    "##### <b>CNN 모델 구조 - 중첩</b>\n",
    "> 합성곱 레이어\n",
    "- 모델 상수(파라미터)를 증가시키면?\n",
    "\n",
    "![image.png](./img/cnn19.png)\n",
    "![image.png](./img/cnn20.png)\n",
    "![image.png](./img/cnn21.png)\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "> 필터 시각화\n",
    "- 학습된 필터 시각화를 통해 각 모델(구조)가 학습한 정보를 이해 가능\n",
    "\n",
    "![image.png](./img/cnn22.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "##### <b>CNN 모델 구조 - 수용영역(Receptive Field)</b>\n",
    "\n",
    "> 중첩과 수용영역\n",
    "- CNN 레이어는 이미지 작은 부분인 '지역 정보'를 추출하는 데에 유리하게 설계\n",
    "- 이미지 활용하는 다양한 작업에서 이미지 전체(예: 맥락) 의미 파악이 필요\n",
    "  <br>따라서 '지역 정보 + 이미지 전체의 맥락'을 이해/활용하기 위한 설계가 필요함.\n",
    "- 수용영역이란?\n",
    "  - CNN이 이미지를 처리하면서 한 번에 볼 수 있는 영역의 크기\n",
    "  - 네트워크의 시야\n",
    "  - 일반적으로 네트워크가 깊어질수록 수용영역도 넓어짐 → 폭 넓은 맥락 이해 가능\n",
    "\n",
    "- 고해상도 이미지 처리 시, 많은 레이어를 통과해야 함.\n",
    "  <br> 연산, 비용, 학습 가능성 고려할 때 비실용적\n",
    "- 실제 해법: 입력 사이즈를 줄여 모델에 입력함.\n",
    "\n",
    "![image.png](./img/cnn23.png)\n",
    "\n",
    "##### <b>CNN 모델 구조 - 풀링</b>\n",
    "> 풀링: 효율적 연산 및 위치 변화의 강건성 확보\n",
    "  - CNN 레이어의 출력을 줄여 연산 효율성을 확보: 입력 크기가 줄면 CNN의 연산량이 크게 줄어듦.\n",
    "  - 예시: 2x2 풀링으로 입력의 해상도가 각각 $\\frac{1}{2}$로 줄었을 경우\n",
    "\n",
    "![image.png](./img/cnn24.png)\n",
    "\n",
    "  - 위치 변화 강건성: 입력 내 객체 위치가 다소 변해도 동일한 출력을 제공\n",
    "  - 사실상 저해상도 정보에 근거하여 작업 수행하므로 몇 화소 이동은 무시됨.\n",
    "\n",
    "  ![image.png](./img/cnn25.png)\n",
    "\n",
    "  - 맥스풀링: 정해진 커널 사이즈(예:2x2)로 이미지를 나누어 각 영역 내 가장 큰 값을 선택하는 연산\n",
    "  \n",
    "  ![image.png](./img/cnn26.png)\n",
    "  \n",
    "##### <b>CNN 모델 구조 - 스트라이드 합성곱</b>\n",
    "> 스트라이드 합성곱: 풀링 한계 개선\n",
    "- 일반 합성곱: 필터를 1칸씩 이동하면서 연산 수행(출력값 계산)\n",
    "- 스트라이드 합성곱: 필터를 스트라이드 값만큼 (S칸) 이동한 후 출력 연산\n",
    "- 효과: 풀링처럼 입력 해상도를 줄임(연산 효율과 위치 강건성)\n",
    "  - 풀링 vs 스트라이드 합성곱: 풀링은 학습 상수가 없지만 스트라이드는 커널을 동시에 학습\n",
    "  - 스트라이드 합성곱은 해상도 저하로 인한 정보 손실이 적고, 풀링 + 합성곱을 하나의 레이어로 대체함\n",
    "  - 고도화된 CNN에서는 스트라이드 합성곱을 풀링 대신 활용되는 경향\n",
    "\n",
    "  ![image.png](./img/cnn27.png)\n",
    "\n",
    "> 스트라이드 2의 사례\n",
    "\n",
    "  ![image.png](./img/cnn28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6181eaac",
   "metadata": {},
   "source": [
    "## 2. CNN 기반 모델 변천사\n",
    "> 2010~2017년까지의 CNN 모델\n",
    "- 세로축: 에려율 (Error Rate, %), 낮을 수록 성능이 좋은 모델\n",
    "- 가로축: (연도 & 모델명)\n",
    "\n",
    "![image.png](./img/cnn29.png)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2-1. AlexNet/VGGNet\n",
    "##### AlexNet\n",
    "> 5개의 합성곱 계층과 3개의 완전연결 계층으로 구성된 8계층 CNN 모델\n",
    "\n",
    "![image.png](./img/cnn30.png)\n",
    "\n",
    "- 모델 구조 특징\n",
    "  > 5개 합성곱 레이어<br>\n",
    "   덱스 풀링<br>\n",
    "   3개 연결층 레이어<br>\n",
    "   ReLU 비선형 활성화<br>\n",
    "   ↓\n",
    "   8-레이어\n",
    "- 입출력\n",
    "  - 입력: 이미지 / 3 x 227 x 227 해상도\n",
    "  - 출력: 레이블 / 1 x 1024 벡터\n",
    "  - 학습 시 정답은 원-핫 벡터(원소 1개만 '1'이고 나머지는 '0'인 벡터)\n",
    "  - 모델 예측값은 0~1 사이 확률 값\n",
    "  - (ImageNet 기준, 각 클래스에 해당할 확률)\n",
    "\n",
    "![image.png](./img/cnn31.png)\n",
    "\n",
    "> Image input 224, 2*GPU\n",
    "- 논문 그림에는 입력 크기가 224로 되어있으나, 227로 정정되었음\n",
    "- 당시 사용된 GPU는 GTX 580으로 메모리가 3GB밖에 되지 않아 2개의 GPU를 병렬 사용하였음\n",
    "  → Conv/FC 레이어를 GPU 2개에 분산 = 채널/뉴런 반씩 나눠 계산\n",
    "\n",
    "  \n",
    "![image.png](./img/cnn32.png)\n",
    "\n",
    "> Image input 227, 1*GPU\n",
    "- 최신 GPU(예: NVIDIA RTX 3090, A100, H100 등) 24GB ~ 80GB VRAM 보유\n",
    "\n",
    "![image.png](./img/cnn33.png)\n",
    "\n",
    "> AlexNet 단계별 구조\n",
    "- 입력 (Input)\n",
    "  - 크기: 227x227x3\n",
    "  - RGB 이미지 (3채널)\n",
    "\n",
    "![image.png](./img/cnn34.png)\n",
    "\n",
    "- 첫 번째 합성곱 층 (Conv1)\n",
    "  - Conv 11x11, stride=4, 96개 필터\n",
    "  - 출력 크기: 55x55x96\n",
    "  - 큰 필터와 stride로 초반에 이미지를 강하게 줄이고 특징 추출 시작\n",
    "\n",
    "![image.png](./img/cnn35.png)\n",
    "\n",
    "- 첫 번째 풀링 층 (Max Pool1)\n",
    "  - Max Pool 3x3, stride=2 (Overlapping Pooling)\n",
    "  - 출력 크기: 27x27x96\n",
    "  - 해상도 절반으로 줄이면서 중요한 특징만 남김\n",
    "\n",
    "![image.png](./img/cnn36.png)\n",
    "\n",
    "- 두 번째  합성곱층 (Conv2)\n",
    "  - Conv 5x5, pad=2, 256개 필터\n",
    "  - 출력 크기: 27x27x96\n",
    "  - padding을 적용해 해상도 유지, 더 복잡한 특징 추출\n",
    "\n",
    "![image.png](./img/cnn37.png)\n",
    "\n",
    "- 두 번째 풀링 층 (Max Pool2)\n",
    "  - Max Pool 3x3, stride=2\n",
    "  - 출력 크기: 13x13x256\n",
    "\n",
    "![image.png](./img/cnn38.png)\n",
    "\n",
    "- 세 번째  합성곱층 (Conv3)\n",
    "  - Conv 3x3, pad=1, 384개 필터\n",
    "  - 출력 크기: 13x13x384\n",
    "\n",
    "![image.png](./img/cnn39.png)\n",
    "\n",
    "- 네 번째  합성곱층 (Conv4)\n",
    "  - Conv 3x3, pad=1, 384개 필터\n",
    "  - 출력 크기: 13x13x384\n",
    "\n",
    "![image.png](./img/cnn40.png)\n",
    "\n",
    "- 다섯 번째  합성곱층 (Conv5)\n",
    "  - Conv 3x3, pad=1, 256개 필터\n",
    "  - 출력 크기: 13x13x256\n",
    "\n",
    "![image.png](./img/cnn41.png)\n",
    "\n",
    "- 세 번째 풀링 층 (Max Pool3)\n",
    "  - Max Pool 3x3, stride=2\n",
    "  - 출력 크기: 6x6x256\n",
    "  - 마지막 공간 축소 → 이후 완전연결층으로 연결하기 쉽게 함\n",
    "\n",
    "![image.png](./img/cnn42.png)\n",
    "\n",
    "- 완전 연결층 (FC Layers)\n",
    "  - Flatten → 벡터 크기: 9216(6x6x256)\n",
    "  - FC1: 4096 뉴런\n",
    "  - FC2: 4096 뉴런\n",
    "\n",
    "![image.png](./img/cnn43.png)\n",
    "\n",
    "- 출력층 (Output)\n",
    "  - FC3: Softmax (1000 클래스)\n",
    "  - ImageNet 1000개 클래스 확률 분포 출력\n",
    "\n",
    "![image.png](./img/cnn44.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b6afbf",
   "metadata": {},
   "source": [
    "<b>강의 자료 p.66까지의 범위</b>\n",
    "\n",
    "https://edu.ssafy.com/data/upload_files/crossUpload/openLrn/ebook/unzip/A2025101613020025500/index.html"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
